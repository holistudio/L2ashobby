{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f01857f",
   "metadata": {},
   "source": [
    "# Pretraining on unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "736134d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a37ebd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chapter 3\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # compute output size of each head\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "            diagonal=1)\n",
    "        )\n",
    "\n",
    "        self.out_proj = nn.Linear(d_out, d_out) # linear layer combines head outputs\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys       = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values   = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        keys       = keys.transpose(1, 2) # (b, num_heads, num_tokens, head_dim)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values   = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) # (b, num_tokens, n_heads, head_dim)\n",
    "\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out) # combine heads\n",
    "\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb1b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5 # in case var is actually 0, add small eps to prevent division by 0\n",
    "\n",
    "        # in case model performance improves without layer norm, \n",
    "        # scale and shift parameters will change significantly during training\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim)) \n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "\n",
    "        # unbiased=False to keep computations consistent with original GPT-2\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76db0cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e391dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), # arbitrary multiply by factor of 4\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b51d9d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = shortcut + x\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = shortcut + x\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd0e0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg)\n",
    "            for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len, device=in_idx.device)\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4cac66",
   "metadata": {},
   "source": [
    "## 5.1 Evaluating generative text models\n",
    "\n",
    "### 5.1.1 Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a082efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f61b74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # only generating, no training\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # only care about the last output vector in the sequence\n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf4d1745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # .unsqueeze(0) adds a dimension for batch\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec40cc",
   "metadata": {},
   "source": [
    "### 5.1.2 Calculating the text generation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4782c174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
    "                        [40, 1107, 588]]) # \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]]) # \" really like chocolate\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "672f8865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b9abe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8b1b7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "# print the estimated probability of the target text, as estimated by the current untrained model\n",
    "\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33fa841a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "617763c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fd9e4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65671ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cdc5bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4477ea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75373a54",
   "metadata": {},
   "source": [
    "### 5.1.3 Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e76ce5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f7c654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3891dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        # super().__init__()\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5402859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length,stride)\n",
    "    dataloader = DataLoader(dataset=dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            drop_last=drop_last,\n",
    "                            num_workers=num_workers) # number of CPU processes\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55342065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9d1f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9a3c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "            input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "957a5477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098150bc",
   "metadata": {},
   "source": [
    "## 5.2 Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5444f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "        model=model, idx=encoded,\n",
    "        max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1651e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval() # disables dropout\n",
    "    with torch.no_grad(): # disables gradient tracking and reduces computations\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e00e47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader,\n",
    "    optimizer, device, num_epochs,\n",
    "    eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, \"\n",
    "                    f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "            generate_and_print_sample(\n",
    "                model, tokenizer, device, start_context\n",
    "            )\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fef9c632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.820, Val loss 9.933\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the the,,,,,,,,,,,,,,,,,,,\n",
      "Every effort moves you,.                                                \n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Every effort moves you,,,,,,, the the,,,,,,,,,,,,,,,, the the,, the,, the the,,,,,,, the the the the,,,,,\n",
      "Ep 1 (Step 000005): Train loss 8.065, Val loss 8.340\n",
      "Every effort moves you the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Every effort moves you, the the the the the the the the the the the the the the the the the the the the the the the                          \n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 2 (Step 000010): Train loss 6.621, Val loss 7.052\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Every effort moves you, the, the the the, the the the, I, the the, I, the the, I, I, the the, I the, I, the, I, the the the, the the the the, the, the the\n",
      "Every effort moves you the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Every effort moves you the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Every effort moves you, the the the the the the the the the the the the the the the the the the the the the the the                          \n",
      "Ep 2 (Step 000015): Train loss 6.047, Val loss 6.600\n",
      "Every effort moves you, the, the the the, the, the, the the, the, the, the the, the, the                          \n",
      "Every effort moves you, the,, the,, the, the, the.                                     \n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "Every effort moves you, and, and, and, and, and, and, and, and,, and,,,,, and, and,, and, and, and,,, and, and, the, and,,, and, and\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "Ep 3 (Step 000020): Train loss 5.586, Val loss 6.479\n",
      "Every effort moves you, and, and the a, and the a, and a.                      \"\"--'s, and, and the of the\", and\n",
      "Every effort moves you, andva ArmstrongNESSNESSNESSNESSNESSNESSNESSNESSNESSNESS jeansNESSNESSNESSNESSNESSNESSNESSNESSき ScoutsきUpき jeansNESSNESSNESS jeans THC accessibilityNESSNESSきき THCきききNESSNESS jeans THCきNESSNESS\n",
      "Every effort moves you the a.                                               \n",
      "Every effort moves you the a of the a the of the of the the of the of the a.                                 \n",
      "Every effort moves you the a of the of the of the of the the of the of the of the of the--'s the of the \" the of the of the of the the of the of the of the of the the of the of the.   \n",
      "Ep 3 (Step 000025): Train loss 5.545, Val loss 6.411\n",
      "Every effort moves you, and, and the of the of the to the of the of the of the of the of the of the of the of the of the the of the of the of the.             \n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "Every effort moves you, and, and, and, and, and, and, and. \", and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and\n",
      "Every effort moves you, and to the to the to the to the to the to the of the of theis to the to theis to the to to the to the to the of the to the to the to the of the to the of theis. G\n",
      "Every effort moves you, and to the to the to the to the to the to the to the of theis to the to theis to the to to the to the to the of the to the to the to the of the to the of theis. G\n",
      "Ep 4 (Step 000030): Train loss 5.155, Val loss 6.366\n",
      "Every effort moves you the sun to the to the to the picture to the \" the to the of the to the \" to the to the                          \n",
      "Every effort moves you the sun to the picture to the picture to the the \" the picture. I had to the \" was--II                          \n",
      "Every effort moves you the sun to the picture the picture to the picture to \" a \" \" a \"--                                \n",
      "Every effort moves you, and he had the picture, and the picture, and a, and a, and he had been, and, and the picture to the the picture, and the to the my to the picture, and, and the of the picture, and\n",
      "Every effort moves you, and my, and the of the picture to the picture. Gisburn, and he had been, and, and, and he had the, and the of the, and he had been, and, and a, and he had the\n",
      "Ep 4 (Step 000035): Train loss 4.986, Val loss 6.384\n",
      "Every effort moves you a a, and a a, and a-- the picture. Gisburn, and a was a--and, and a. G. I had a of the a, and a. I had the of the a of the of the of\n",
      "Every effort moves you a the picture. Gisburn was a-- the picture. Gisburn, and he was a--and was a was a of the the picture of the of the picture. Gisburn, and he was a of the of the of\n",
      "Every effort moves you, and I had been the of the picture to the picture. Gisburn, and I was, and I was, and I was a was a was a was a was a was the was a was a was a was.   \n",
      "Every effort moves you, and I was a picture, I was a, I was, I was, I was was, I was, I was to have, I was, I was, I was was the picture, I was a was, I was, I\n",
      "Every effort moves you, and I was a picture, I was not, I was.                                    \n",
      "Ep 5 (Step 000040): Train loss 4.324, Val loss 6.246\n",
      "Every effort moves you, I was, I was, I was to the picture.                                     \n",
      "Every effort moves you, I was, I was, I was the, I had been.                                   \n",
      "Every effort moves you, I was, I was, I was a, I had been.             \"I said--as I had been the picture.           \n",
      "Every effort moves you, I had been the picture, I had to the picture.  \".     \"I \"I turned. \"--as of the picture.   \"I said.  \"I had been\n",
      "Every effort moves you, one of the of the of the picture to the picture.  \"Oh, I had been--and it's had been. \"Oh, I had been the picture--and it to me, and I had been. \"\n",
      "Ep 6 (Step 000045): Train loss 4.025, Val loss 6.231\n",
      "Every effort moves you, one of the picture. \"Oh, in a little me. \"Oh, in the picture to me, and I felt. \"Oh, as a little.   \"I, and down, in a little of\n",
      "Every effort moves you, and, and, in a of the picture, and I had been, and, as a, as a little of the picture to me.    \"I had been. \"I, and down, as a little of\n",
      "Every effort moves you, and, and, in, in the picture, and I had been, and, with a, as a little, as to see. \"--as Jack himself, as, and I had been, and down, as, as of\n",
      "Every effort moves you, and to have to the picture.  \"I had been.             \"I, and I had been the donkey, and I had the donkey, and I had been the first\n",
      "Every effort moves you know the fact of the picture and I had to have to have to see it.                                 \n",
      "Ep 6 (Step 000050): Train loss 3.546, Val loss 6.193\n",
      "Every effort moves you know the fact of the picture to have to see the                                       \n",
      "Every effort moves you know the fact, and I felt--I had been the first, with a little: \"--I had been, and had been to the picture, with a little to have to have to have to the donkey, and I had been the first\n",
      "Every effort moves you, with a, and I felt--I had the fact.                                     \n",
      "Every effort moves you, and, and in the picture.                    \"Oh, and I had been the donkey.            \n",
      "Every effort moves you know the \"Oh, and in the fact his pictures.               \"Oh, and I had been the donkey.  \"I, and down the room, and I\n",
      "Ep 7 (Step 000055): Train loss 3.582, Val loss 6.190\n",
      "Every effort moves you know the \"Oh, and in the \"Oh, and in a little: \"Yes, and in fact, and to see.       \"Oh, and he had been the man of the picture. \n",
      "Every effort moves you know to see the picture--I had been to the fact of the last word.           \"Oh, and I had always at my elbow and I had the donkey, and in the picture. \n",
      "Every effort moves you know to have to the picture to have to the picture--as of the fact of the picture--the--and here are the Riv you of the moment--as Jack himself at the fact of the Riv of the picture--the, and in the\n",
      "Every effort moves you know the fact, and pushed one of the to the fact of the last word.           \"Oh, and I had always at the picture. \"I looked, and, and he was his\n",
      "Every effort moves you know the fact, and pushed one of the Riv, and he was not--the, and to have to the fact, and. \"Oh, and I had been at my elbow and as he had been the picture, and he was his\n",
      "Ep 7 (Step 000060): Train loss 2.775, Val loss 6.165\n",
      "Every effort moves you know the picture, and pushed one of the Riv, and I had been.            \"I was his pictures--as, and he was dead, I had the picture, and he was his\n",
      "Every effort moves you know the picture, and pushed one of the Riv, and I felt.             \"I didn't I had always, and he was dead, I had the picture.    \n",
      "Every effort moves you know to have to the picture, I was to the fact of the last word.                   \"I looked. I was, and down the room, I was\n",
      "Every effort moves you know he was to my dear, I was to the fact that, I had not to have to see that one of Jack's that, and I felt back his pictures--I had been.           \n",
      "Every effort moves you know he was his pictures--I had been to the fact of the last word.                   \"I looked up his pictures--I looked up at the first his\n",
      "Ep 8 (Step 000065): Train loss 2.336, Val loss 6.151\n",
      "Every effort moves you know he was, and pushed one of the deep arm-chairs forward.             \"I he was his pictures--and him--and it, and I was his pictures--and by his\n",
      "Every effort moves you know it was not to the picture.  \"I had the last word.           \"I he had the fact, and my elbow and I had the donkey, and it, I was his\n",
      "Every effort moves you know,\" was, and pushed one of the deep arm-chairs forward. \"I looked, I had the fact, and that, and I was his pictures--and it--and the fact, and up and down the room, when I\n",
      "Every effort moves you know the fact, and pushed one of the deep arm-chairs forward. \"I looked, I had the fact, with that, in the moment--as Jack himself, as he had always, the donkey.    \"I\n",
      "Every effort moves you know,\" was, and pushed one of the deep arm-chairs forward. \"There: \"Yes, with the fact, as a deprecating of his painting.  \"Oh, I had the donkey. \"There were days when I\n",
      "Ep 8 (Step 000070): Train loss 1.984, Val loss 6.201\n",
      "Every effort moves you know,\" was, and pushed one of the deep arm-chairs forward. \"There: make yourself comfortable--and here are the cigars you like.\"    \"I had been. \"I had a little the room, I had\n",
      "Every effort moves you know,\" was, and pushed one of the deep arm-chairs forward. \"There: make yourself comfortable--and here are the cigars you like.\"    \"I had been his painting, the donkey. \"There were days, in\n",
      "Every effort moves you know,\" was one of the picture. Gisburn--as such--had not to my work, and up, I had been to the end of his painting. Gisburn's an his own of Jack's \"There were, I had\n",
      "Every effort moves you know,\" was not that the picture for a smile that lifted the picture. Gisburn--and by me to see it was. Gisburn, and I had been his pictures--and it, the donkey. \"There were, as his\n",
      "Every effort moves you know,\" was not that the picture for the deep arm-chairs forward. I had been his own's an!             \"Oh, and I said, and down the room, and I\n",
      "Ep 9 (Step 000075): Train loss 1.619, Val loss 6.225\n",
      "Every effort moves you know,\" was not that the picture for the deep arm-chairs forward. I had been his own's past!             \"Oh, I saw that, and down the room, with a\n",
      "Every effort moves you know,\" was not that the picture for nothing--I had been.              \"I turned back his head to the donkey.            \n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that I had been: make yourself comfortable--and here are the cigars you like.\"      \"Oh, I had the donkey.      \n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that I had been with a smile's past!  \"Oh, in the moment--as Jack himself, as once one had been the donkey. \"--I was.\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that I had been that he had been--and here are the cigars you like.\"  \"Oh, as his pictures--the quality of Jack's \"There were days when I\n",
      "Ep 9 (Step 000080): Train loss 1.281, Val loss 6.269\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on the last word.    \"I looked, and to see a smile behind his pictures with a little him. \"Oh, I was \"There were days when I\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on the last word. Gisburn's past!  \"Oh, and I remember getting off a prodigious phrase about the honour being _mine_--because he had always _\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on the last word. Gisburn's past!     \"Oh, and his head to look up at the honour being _mine_--because he had always _\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me to me to have to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"    \"Oh, and back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.984, Val loss 6.296\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  \"Oh, I felt it back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Every effort moves you?\" \"I didn't face it was the the fact with a laugh: \"Yes--and by me!\"  \"I didn't dabble back his head to look up at the honour being _mine_--because he had always _\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  \"I didn't dabble back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  \"I didn't dabble back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8faec5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "    epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7631e8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bf0f4d",
   "metadata": {},
   "source": [
    "## 5.3 Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30ed22ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d7eb3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fef96a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45b5a852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6d22bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17b3869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f733e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5931712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45f92c6",
   "metadata": {},
   "source": [
    "**Exercise 5.1**\n",
    "\n",
    "Use the print_sampled_tokens function to print the sampling frequencies of the softmax probabilities scaled with the temperatures shown in figure 5.14. How often is the word pizza sampled in each case? Can you think of a faster and more accurate way to determine how often the word pizza is sampled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c190390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2d3cfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "099aff83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5744ca04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4622ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "    temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6e8d257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you in,\" she up surprise. Th--I felt nervous portrait by his knees\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03bdcc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05d69bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b207af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a36584db",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776addd0",
   "metadata": {},
   "source": [
    "## 5.5 Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3e2f312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x290855744d0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "719c7c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 158kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 3.07MiB/s]\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 203kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:35<00:00, 14.2MiB/s] \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 9.23MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 2.14MiB/s]\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.67MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5264b7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "804aeb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b0965ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2a50d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9cba8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_length\": 1024})  # original GPT-2 models from OpenAI were trained with a 1,024-token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b1bdd67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"qkv_bias\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c63068f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c3434937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                         \"Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2becf253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01afdc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93df5238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you as far as the hand can go until the end of your turn unless something interrupts your control flow. As you may observe I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8d874b",
   "metadata": {},
   "source": [
    "**Exercise 5.5**\n",
    "\n",
    "Calculate the training and validation set losses of the GPTModel with the pretrained weights from OpenAI on the “The Verdict” dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d960803d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1744a63",
   "metadata": {},
   "source": [
    "**Excercise 5.6**\n",
    "\n",
    "Experiment with GPT-2 models of different sizes—for example, the largest 1,558 million parameter model—and compare the generated text to the 124 million model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc116ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
